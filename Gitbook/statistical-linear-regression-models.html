<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>20 Statistical Linear Regression Models | Analysis Notes</title>
  <meta name="description" content="20 Statistical Linear Regression Models | Analysis Notes" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="20 Statistical Linear Regression Models | Analysis Notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="20 Statistical Linear Regression Models | Analysis Notes" />
  
  
  

<meta name="author" content="Jack Quarm 21/03/20" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="quiz-1.html"/>
<link rel="next" href="prediction.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction-to-stats-expected-values.html"><a href="introduction-to-stats-expected-values.html"><i class="fa fa-check"></i><b>1</b> Introduction to Stats: Expected values</a></li>
<li class="chapter" data-level="2" data-path="example-population-mean.html"><a href="example-population-mean.html"><i class="fa fa-check"></i><b>2</b> Example Population Mean</a><ul>
<li class="chapter" data-level="2.1" data-path="example-population-mean.html"><a href="example-population-mean.html#example"><i class="fa fa-check"></i><b>2.1</b> Example</a></li>
<li class="chapter" data-level="2.2" data-path="example-population-mean.html"><a href="example-population-mean.html#example-1"><i class="fa fa-check"></i><b>2.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html"><i class="fa fa-check"></i><b>3</b> Continuous Random Variables</a></li>
<li class="chapter" data-level="4" data-path="variability.html"><a href="variability.html"><i class="fa fa-check"></i><b>4</b> Variability</a><ul>
<li class="chapter" data-level="4.1" data-path="variability.html"><a href="variability.html#example-for-coin-toss"><i class="fa fa-check"></i><b>4.1</b> Example For Coin Toss</a></li>
<li class="chapter" data-level="4.2" data-path="variability.html"><a href="variability.html#sample-variance"><i class="fa fa-check"></i><b>4.2</b> Sample Variance</a></li>
<li class="chapter" data-level="4.3" data-path="variability.html"><a href="variability.html#simulation-example"><i class="fa fa-check"></i><b>4.3</b> Simulation Example</a></li>
<li class="chapter" data-level="4.4" data-path="variability.html"><a href="variability.html#data-example"><i class="fa fa-check"></i><b>4.4</b> Data Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>5</b> Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="distributions.html"><a href="distributions.html#bernoulli-distribution-binomial"><i class="fa fa-check"></i><b>5.1</b> Bernoulli Distribution (Binomial)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="distributions.html"><a href="distributions.html#binomial-trails"><i class="fa fa-check"></i><b>5.1.1</b> Binomial Trails</a></li>
<li class="chapter" data-level="5.1.2" data-path="distributions.html"><a href="distributions.html#example-2"><i class="fa fa-check"></i><b>5.1.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="5.2.1" data-path="distributions.html"><a href="distributions.html#examples"><i class="fa fa-check"></i><b>5.2.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="distributions.html"><a href="distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>5.3</b> Poisson Distribution</a><ul>
<li class="chapter" data-level="5.3.1" data-path="distributions.html"><a href="distributions.html#uses-of-the-poisson-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Uses of the Poisson Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="distributions.html"><a href="distributions.html#rates-and-poisson-random-variables"><i class="fa fa-check"></i><b>5.3.2</b> Rates and Poisson Random Variables</a></li>
<li class="chapter" data-level="5.3.3" data-path="distributions.html"><a href="distributions.html#example-3"><i class="fa fa-check"></i><b>5.3.3</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>6</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="6.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#examples-1"><i class="fa fa-check"></i><b>6.1</b> Examples</a><ul>
<li class="chapter" data-level="6.1.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#coin-clt"><i class="fa fa-check"></i><b>6.1.1</b> Coin CLT</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>7</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="7.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#example-give-ci-for-the-average-sons-height"><i class="fa fa-check"></i><b>7.1</b> Example: Give CI for the average Son’s height</a></li>
<li class="chapter" data-level="7.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#sample-proportions"><i class="fa fa-check"></i><b>7.2</b> Sample Proportions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#example-4"><i class="fa fa-check"></i><b>7.2.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#binomial-interval"><i class="fa fa-check"></i><b>7.3</b> Binomial Interval</a><ul>
<li class="chapter" data-level="7.3.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#small-n-values"><i class="fa fa-check"></i><b>7.3.1</b> Small <span class="math inline">\(n\)</span> Values</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#poisson-interval"><i class="fa fa-check"></i><b>7.4</b> Poisson Interval</a></li>
<li class="chapter" data-level="7.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#simulating-poisson-coverage"><i class="fa fa-check"></i><b>7.5</b> Simulating Poisson Coverage</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="t-confidence-intervals.html"><a href="t-confidence-intervals.html"><i class="fa fa-check"></i><b>8</b> T Confidence Intervals</a><ul>
<li class="chapter" data-level="8.1" data-path="t-confidence-intervals.html"><a href="t-confidence-intervals.html#gussets-t-distribution"><i class="fa fa-check"></i><b>8.1</b> Gusset’s <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="8.2" data-path="t-confidence-intervals.html"><a href="t-confidence-intervals.html#notes-about-the-t-interval"><i class="fa fa-check"></i><b>8.2</b> Notes about the <span class="math inline">\(t\)</span> interval</a></li>
<li class="chapter" data-level="8.3" data-path="t-confidence-intervals.html"><a href="t-confidence-intervals.html#sleep-data"><i class="fa fa-check"></i><b>8.3</b> Sleep Data</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html"><i class="fa fa-check"></i><b>9</b> Independent Group T-Intervals</a><ul>
<li class="chapter" data-level="9.1" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>9.1</b> Confidence Interval</a></li>
<li class="chapter" data-level="9.2" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#example-5"><i class="fa fa-check"></i><b>9.2</b> Example</a></li>
<li class="chapter" data-level="9.3" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#example-chick-weight"><i class="fa fa-check"></i><b>9.3</b> Example Chick Weight</a></li>
<li class="chapter" data-level="9.4" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#dealing-with-unequal-variances"><i class="fa fa-check"></i><b>9.4</b> Dealing with Unequal Variances</a></li>
<li class="chapter" data-level="9.5" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#example-6"><i class="fa fa-check"></i><b>9.5</b> Example</a></li>
<li class="chapter" data-level="9.6" data-path="independent-group-t-intervals.html"><a href="independent-group-t-intervals.html#comparing-other-kinds-of-data"><i class="fa fa-check"></i><b>9.6</b> Comparing Other Kinds of Data</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Tests</a><ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#hypothesis-testing"><i class="fa fa-check"></i><b>10.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#example-7"><i class="fa fa-check"></i><b>10.2</b> Example</a></li>
<li class="chapter" data-level="10.3" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#discussion"><i class="fa fa-check"></i><b>10.3</b> Discussion</a></li>
<li class="chapter" data-level="10.4" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#our-last-example"><i class="fa fa-check"></i><b>10.4</b> Our Last Example</a></li>
<li class="chapter" data-level="10.5" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#t-tests"><i class="fa fa-check"></i><b>10.5</b> T-Tests</a><ul>
<li class="chapter" data-level="10.5.1" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#example-reconsidered"><i class="fa fa-check"></i><b>10.5.1</b> Example Reconsidered</a></li>
<li class="chapter" data-level="10.5.2" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#two-sided-tests"><i class="fa fa-check"></i><b>10.5.2</b> Two Sided Tests</a></li>
<li class="chapter" data-level="10.5.3" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#t-test-in-r"><i class="fa fa-check"></i><b>10.5.3</b> T Test in R</a></li>
<li class="chapter" data-level="10.5.4" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#connections-with-confidence-intervals"><i class="fa fa-check"></i><b>10.5.4</b> Connections with Confidence Intervals</a></li>
<li class="chapter" data-level="10.5.5" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#two-group-intervals"><i class="fa fa-check"></i><b>10.5.5</b> Two Group Intervals</a></li>
<li class="chapter" data-level="10.5.6" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#example-8"><i class="fa fa-check"></i><b>10.5.6</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>11</b> P-Values</a><ul>
<li class="chapter" data-level="11.1" data-path="p-values.html"><a href="p-values.html#what-is-a-p-value"><i class="fa fa-check"></i><b>11.1</b> What is a P Value?</a></li>
<li class="chapter" data-level="11.2" data-path="p-values.html"><a href="p-values.html#the-attained-significance-level"><i class="fa fa-check"></i><b>11.2</b> The Attained Significance Level</a></li>
<li class="chapter" data-level="11.3" data-path="p-values.html"><a href="p-values.html#example-of-your-friend-having-children"><i class="fa fa-check"></i><b>11.3</b> Example of Your Friend Having Children</a></li>
<li class="chapter" data-level="11.4" data-path="p-values.html"><a href="p-values.html#poisson-example"><i class="fa fa-check"></i><b>11.4</b> Poisson Example</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="power.html"><a href="power.html"><i class="fa fa-check"></i><b>12</b> Power</a><ul>
<li class="chapter" data-level="12.1" data-path="power.html"><a href="power.html#example-9"><i class="fa fa-check"></i><b>12.1</b> Example</a></li>
<li class="chapter" data-level="12.2" data-path="power.html"><a href="power.html#calculating-power"><i class="fa fa-check"></i><b>12.2</b> Calculating Power</a></li>
<li class="chapter" data-level="12.3" data-path="power.html"><a href="power.html#example-continued"><i class="fa fa-check"></i><b>12.3</b> Example Continued</a></li>
<li class="chapter" data-level="12.4" data-path="power.html"><a href="power.html#question"><i class="fa fa-check"></i><b>12.4</b> Question</a></li>
<li class="chapter" data-level="12.5" data-path="power.html"><a href="power.html#notes"><i class="fa fa-check"></i><b>12.5</b> Notes:</a></li>
<li class="chapter" data-level="12.6" data-path="power.html"><a href="power.html#t-test-power"><i class="fa fa-check"></i><b>12.6</b> T-Test Power</a><ul>
<li class="chapter" data-level="12.6.1" data-path="power.html"><a href="power.html#example-10"><i class="fa fa-check"></i><b>12.6.1</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>13</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="13.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multiple-testing"><i class="fa fa-check"></i><b>13.1</b> Multiple Testing</a><ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#key-ideas"><i class="fa fa-check"></i><b>13.1.1</b> Key Ideas</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#why-correct-for-multiple-tests"><i class="fa fa-check"></i><b>13.1.2</b> Why Correct for Multiple Tests?</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#error-rates"><i class="fa fa-check"></i><b>13.2</b> Error Rates</a></li>
<li class="chapter" data-level="13.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#controlling-the-false-positive-rate"><i class="fa fa-check"></i><b>13.3</b> Controlling the False Positive Rate</a><ul>
<li class="chapter" data-level="13.3.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#controlling-the-family-wise-error-rate"><i class="fa fa-check"></i><b>13.3.1</b> Controlling the Family-wise Error Rate</a></li>
<li class="chapter" data-level="13.3.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#controlling-the-false-discovery-rate-fdr"><i class="fa fa-check"></i><b>13.3.2</b> Controlling the False Discovery Rate (FDR)</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#adjusted-p-values"><i class="fa fa-check"></i><b>13.4</b> Adjusted P-Values</a></li>
<li class="chapter" data-level="13.5" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#case-study-1-no-true-positives"><i class="fa fa-check"></i><b>13.5</b> Case Study 1: No True Positives</a></li>
<li class="chapter" data-level="13.6" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#case-study-2-50-true-positives"><i class="fa fa-check"></i><b>13.6</b> Case Study 2: 50% True Positives</a></li>
<li class="chapter" data-level="13.7" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#notes-1"><i class="fa fa-check"></i><b>13.7</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>14</b> Resampling</a><ul>
<li class="chapter" data-level="14.1" data-path="resampling.html"><a href="resampling.html#the-bootstrap"><i class="fa fa-check"></i><b>14.1</b> The Bootstrap</a></li>
<li class="chapter" data-level="14.2" data-path="resampling.html"><a href="resampling.html#example-11"><i class="fa fa-check"></i><b>14.2</b> Example</a></li>
<li class="chapter" data-level="14.3" data-path="resampling.html"><a href="resampling.html#the-principle"><i class="fa fa-check"></i><b>14.3</b> The Principle</a></li>
<li class="chapter" data-level="14.4" data-path="resampling.html"><a href="resampling.html#nonparametric-bootstrap-algorithm-example"><i class="fa fa-check"></i><b>14.4</b> Nonparametric Bootstrap Algorithm Example</a></li>
<li class="chapter" data-level="14.5" data-path="resampling.html"><a href="resampling.html#example-12"><i class="fa fa-check"></i><b>14.5</b> Example:</a></li>
<li class="chapter" data-level="14.6" data-path="resampling.html"><a href="resampling.html#notes-2"><i class="fa fa-check"></i><b>14.6</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="permutation-tests.html"><a href="permutation-tests.html"><i class="fa fa-check"></i><b>15</b> Permutation Tests</a><ul>
<li class="chapter" data-level="15.1" data-path="permutation-tests.html"><a href="permutation-tests.html#group-comparisons"><i class="fa fa-check"></i><b>15.1</b> Group Comparisons</a></li>
<li class="chapter" data-level="15.2" data-path="permutation-tests.html"><a href="permutation-tests.html#variations-on-permutation-testing"><i class="fa fa-check"></i><b>15.2</b> Variations on Permutation Testing</a></li>
<li class="chapter" data-level="15.3" data-path="permutation-tests.html"><a href="permutation-tests.html#permutation-test-b-v-c"><i class="fa fa-check"></i><b>15.3</b> Permutation Test B v C</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html"><i class="fa fa-check"></i><b>16</b> Intro to Linear Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html#intro-basic-least-squares"><i class="fa fa-check"></i><b>16.1</b> Intro: Basic Least Squares</a><ul>
<li class="chapter" data-level="16.1.1" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html#finding-the-middle-via-least-squares"><i class="fa fa-check"></i><b>16.1.1</b> Finding the Middle via Least Squares</a></li>
<li class="chapter" data-level="16.1.2" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html#proof-that-bary-is-the-minimiser"><i class="fa fa-check"></i><b>16.1.2</b> Proof that <span class="math inline">\(\bar{Y}\)</span> is the minimiser</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html#comparing-childrens-heights-to-their-parentss-heights"><i class="fa fa-check"></i><b>16.2</b> Comparing children’s heights to their parents’s heights</a></li>
<li class="chapter" data-level="16.3" data-path="intro-to-linear-regression.html"><a href="intro-to-linear-regression.html#regression-through-the-origin"><i class="fa fa-check"></i><b>16.3</b> Regression through the Origin</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="linear-least-squares.html"><a href="linear-least-squares.html"><i class="fa fa-check"></i><b>17</b> Linear Least Squares</a><ul>
<li class="chapter" data-level="17.1" data-path="linear-least-squares.html"><a href="linear-least-squares.html#notation-for-data"><i class="fa fa-check"></i><b>17.1</b> Notation for data</a><ul>
<li class="chapter" data-level="17.1.1" data-path="linear-least-squares.html"><a href="linear-least-squares.html#the-empirical-mean"><i class="fa fa-check"></i><b>17.1.1</b> The empirical mean</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="linear-least-squares.html"><a href="linear-least-squares.html#the-empirical-standard-deviation-and-variance"><i class="fa fa-check"></i><b>17.2</b> The empirical standard deviation and variance</a></li>
<li class="chapter" data-level="17.3" data-path="linear-least-squares.html"><a href="linear-least-squares.html#normalisation"><i class="fa fa-check"></i><b>17.3</b> Normalisation</a></li>
<li class="chapter" data-level="17.4" data-path="linear-least-squares.html"><a href="linear-least-squares.html#the-empirical-covariance"><i class="fa fa-check"></i><b>17.4</b> The Empirical Covariance</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html"><i class="fa fa-check"></i><b>18</b> Least Squares Estimation</a><ul>
<li class="chapter" data-level="18.1" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#results"><i class="fa fa-check"></i><b>18.1</b> Results</a></li>
<li class="chapter" data-level="18.2" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#linear-least-squares-coding-example"><i class="fa fa-check"></i><b>18.2</b> Linear Least Squares Coding Example</a></li>
<li class="chapter" data-level="18.3" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#normalising-variables-results-in-the-slope-being-the-correlation"><i class="fa fa-check"></i><b>18.3</b> Normalising variables results in the slope being the correlation</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="quiz-1.html"><a href="quiz-1.html"><i class="fa fa-check"></i><b>19</b> Quiz 1:</a></li>
<li class="chapter" data-level="20" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html"><i class="fa fa-check"></i><b>20</b> Statistical Linear Regression Models</a><ul>
<li class="chapter" data-level="20.1" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#basic-regression-model-with-additive-gaussian-errors"><i class="fa fa-check"></i><b>20.1</b> Basic Regression Model with Additive Gaussian Errors</a></li>
<li class="chapter" data-level="20.2" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#interpreting-coefficients"><i class="fa fa-check"></i><b>20.2</b> Interpreting Coefficients</a></li>
<li class="chapter" data-level="20.3" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#linear-regression-for-prediction"><i class="fa fa-check"></i><b>20.3</b> Linear Regression for Prediction</a><ul>
<li class="chapter" data-level="20.3.1" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#fitting-the-linear-regression-model"><i class="fa fa-check"></i><b>20.3.1</b> Fitting the Linear Regression Model</a></li>
<li class="chapter" data-level="20.3.2" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#getting-a-more-interpretable-result"><i class="fa fa-check"></i><b>20.3.2</b> Getting a More Interpretable Result</a></li>
<li class="chapter" data-level="20.3.3" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#predicting-the-price-of-a-diamond"><i class="fa fa-check"></i><b>20.3.3</b> Predicting the Price of a Diamond</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#residuals-and-residual-variation"><i class="fa fa-check"></i><b>20.4</b> Residuals and Residual Variation</a><ul>
<li class="chapter" data-level="20.4.1" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#motivating-example"><i class="fa fa-check"></i><b>20.4.1</b> Motivating example</a></li>
<li class="chapter" data-level="20.4.2" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#properties-of-the-residuals"><i class="fa fa-check"></i><b>20.4.2</b> Properties of the Residuals</a></li>
<li class="chapter" data-level="20.4.3" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#non-linear-data"><i class="fa fa-check"></i><b>20.4.3</b> Non Linear Data</a></li>
<li class="chapter" data-level="20.4.4" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#heteroskedasticity"><i class="fa fa-check"></i><b>20.4.4</b> Heteroskedasticity</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#estimating-residual-variation"><i class="fa fa-check"></i><b>20.5</b> Estimating Residual Variation</a></li>
<li class="chapter" data-level="20.6" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#r-squared"><i class="fa fa-check"></i><b>20.6</b> R Squared</a><ul>
<li class="chapter" data-level="20.6.1" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#example-13"><i class="fa fa-check"></i><b>20.6.1</b> Example:</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#inference-in-regression"><i class="fa fa-check"></i><b>20.7</b> Inference in Regression</a><ul>
<li class="chapter" data-level="20.7.1" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#hand-rolling-the-linear-regression-function"><i class="fa fa-check"></i><b>20.7.1</b> Hand-rolling the linear regression function</a></li>
<li class="chapter" data-level="20.7.2" data-path="statistical-linear-regression-models.html"><a href="statistical-linear-regression-models.html#getting-a-confidence-interval"><i class="fa fa-check"></i><b>20.7.2</b> Getting a Confidence Interval</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>21</b> Prediction</a><ul>
<li class="chapter" data-level="21.1" data-path="prediction.html"><a href="prediction.html#prediction-of-outcomes"><i class="fa fa-check"></i><b>21.1</b> Prediction of Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="quiz-2.html"><a href="quiz-2.html"><i class="fa fa-check"></i><b>22</b> Quiz 2:</a></li>
<li class="chapter" data-level="23" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html"><i class="fa fa-check"></i><b>23</b> Multivariable Regression Analysis</a><ul>
<li class="chapter" data-level="23.1" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#how-to-get-estimates"><i class="fa fa-check"></i><b>23.1</b> How to Get Estimates</a></li>
<li class="chapter" data-level="23.2" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#interprettion-of-the-model-coefficients-wrt-the-model"><i class="fa fa-check"></i><b>23.2</b> Interprettion of the model coefficients wrt the model</a></li>
<li class="chapter" data-level="23.3" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#fitted-values-residuals-and-residual"><i class="fa fa-check"></i><b>23.3</b> Fitted values, residuals and residual</a></li>
<li class="chapter" data-level="23.4" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#multivariable-regression-examples"><i class="fa fa-check"></i><b>23.4</b> Multivariable Regression Examples</a></li>
<li class="chapter" data-level="23.5" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#dummy-variables-are-smart"><i class="fa fa-check"></i><b>23.5</b> Dummy Variables are Smart</a></li>
<li class="chapter" data-level="23.6" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#more-multivariable-regression-examples"><i class="fa fa-check"></i><b>23.6</b> More Multivariable Regression Examples</a><ul>
<li class="chapter" data-level="23.6.1" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#two-lines-two-intercepts"><i class="fa fa-check"></i><b>23.6.1</b> Two lines, two intercepts</a></li>
<li class="chapter" data-level="23.6.2" data-path="multivariable-regression-analysis.html"><a href="multivariable-regression-analysis.html#interaction-term-two-lines-two-slopes-two-intercepts"><i class="fa fa-check"></i><b>23.6.2</b> Interaction term: Two lines, two slopes, two intercepts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="adjustment.html"><a href="adjustment.html"><i class="fa fa-check"></i><b>24</b> Adjustment</a><ul>
<li class="chapter" data-level="24.1" data-path="adjustment.html"><a href="adjustment.html#coefficient-of-interest"><i class="fa fa-check"></i><b>24.1</b> Coefficient of interest</a></li>
<li class="chapter" data-level="24.2" data-path="adjustment.html"><a href="adjustment.html#adjustment-examples"><i class="fa fa-check"></i><b>24.2</b> Adjustment examples</a><ul>
<li class="chapter" data-level="24.2.1" data-path="adjustment.html"><a href="adjustment.html#simulation-1"><i class="fa fa-check"></i><b>24.2.1</b> Simulation 1:</a></li>
<li class="chapter" data-level="24.2.2" data-path="adjustment.html"><a href="adjustment.html#simulation-2"><i class="fa fa-check"></i><b>24.2.2</b> Simulation 2:</a></li>
<li class="chapter" data-level="24.2.3" data-path="adjustment.html"><a href="adjustment.html#simulation-3"><i class="fa fa-check"></i><b>24.2.3</b> Simulation 3:</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="adjustment.html"><a href="adjustment.html#final-thoughts"><i class="fa fa-check"></i><b>24.3</b> Final thoughts</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html"><i class="fa fa-check"></i><b>25</b> Residuals Diagnostics and Variation</a><ul>
<li class="chapter" data-level="25.0.1" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#influential-high-leverage-and-outlying-points"><i class="fa fa-check"></i><b>25.0.1</b> Influential, High Leverage and Outlying Points</a></li>
<li class="chapter" data-level="25.0.2" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#summary-of-the-plot"><i class="fa fa-check"></i><b>25.0.2</b> Summary of the plot</a></li>
<li class="chapter" data-level="25.1" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#influence-measures"><i class="fa fa-check"></i><b>25.1</b> Influence Measures</a><ul>
<li class="chapter" data-level="25.1.1" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#case-1-linear-trend-when-there-should-not-be"><i class="fa fa-check"></i><b>25.1.1</b> Case 1: Linear Trend when there should not be</a></li>
<li class="chapter" data-level="25.1.2" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#case-2-linear-trend-with-outlier"><i class="fa fa-check"></i><b>25.1.2</b> Case 2: Linear trend with outlier</a></li>
<li class="chapter" data-level="25.1.3" data-path="residuals-diagnostics-and-variation.html"><a href="residuals-diagnostics-and-variation.html#the-plot-summary"><i class="fa fa-check"></i><b>25.1.3</b> The Plot Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>26</b> Model Selection</a><ul>
<li class="chapter" data-level="26.1" data-path="model-selection.html"><a href="model-selection.html#multiple-variables"><i class="fa fa-check"></i><b>26.1</b> Multiple Variables</a></li>
<li class="chapter" data-level="26.2" data-path="model-selection.html"><a href="model-selection.html#variance-inflation"><i class="fa fa-check"></i><b>26.2</b> Variance Inflation</a></li>
<li class="chapter" data-level="26.3" data-path="model-selection.html"><a href="model-selection.html#variable-inclusion-and-exclusion"><i class="fa fa-check"></i><b>26.3</b> Variable Inclusion and Exclusion</a></li>
<li class="chapter" data-level="26.4" data-path="model-selection.html"><a href="model-selection.html#predicting-medical-expenses-using-mlr"><i class="fa fa-check"></i><b>26.4</b> Predicting Medical Expenses using MLR</a><ul>
<li class="chapter" data-level="26.4.1" data-path="model-selection.html"><a href="model-selection.html#evaluating-model-performance"><i class="fa fa-check"></i><b>26.4.1</b> Evaluating Model Performance</a></li>
<li class="chapter" data-level="26.4.2" data-path="model-selection.html"><a href="model-selection.html#improving-model-performance"><i class="fa fa-check"></i><b>26.4.2</b> Improving Model Performance</a></li>
<li class="chapter" data-level="26.4.3" data-path="model-selection.html"><a href="model-selection.html#transformations---converting-a-numeric-variable-to-a-binary-indicator"><i class="fa fa-check"></i><b>26.4.3</b> Transformations - Converting a numeric variable to a binary indicator</a></li>
<li class="chapter" data-level="26.4.4" data-path="model-selection.html"><a href="model-selection.html#model-specification-adding-interaction-effects"><i class="fa fa-check"></i><b>26.4.4</b> Model Specification: Adding interaction effects</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="model-selection.html"><a href="model-selection.html#putting-it-all-together-an-impoved-regression-model"><i class="fa fa-check"></i><b>26.5</b> Putting it all Together: An Impoved Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="regression-trees-and-model-trees.html"><a href="regression-trees-and-model-trees.html"><i class="fa fa-check"></i><b>27</b> Regression Trees and Model Trees</a><ul>
<li class="chapter" data-level="27.1" data-path="regression-trees-and-model-trees.html"><a href="regression-trees-and-model-trees.html#building-the-model"><i class="fa fa-check"></i><b>27.1</b> Building the Model</a></li>
<li class="chapter" data-level="27.2" data-path="regression-trees-and-model-trees.html"><a href="regression-trees-and-model-trees.html#evaluating-the-model"><i class="fa fa-check"></i><b>27.2</b> Evaluating the Model</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="quiz-3.html"><a href="quiz-3.html"><i class="fa fa-check"></i><b>28</b> Quiz 3</a></li>
<li class="chapter" data-level="29" data-path="introduction-to-generalized-linear-models.html"><a href="introduction-to-generalized-linear-models.html"><i class="fa fa-check"></i><b>29</b> Introduction to Generalized Linear Models</a></li>
<li class="chapter" data-level="30" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html"><i class="fa fa-check"></i><b>30</b> Generalised Linear Models</a><ul>
<li class="chapter" data-level="30.1" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#linear-models"><i class="fa fa-check"></i><b>30.1</b> Linear Models</a></li>
<li class="chapter" data-level="30.2" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#generalised-linear-models-1"><i class="fa fa-check"></i><b>30.2</b> Generalised Linear Models</a></li>
<li class="chapter" data-level="30.3" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#example-linear-models"><i class="fa fa-check"></i><b>30.3</b> Example: Linear Models</a></li>
<li class="chapter" data-level="30.4" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#example-logistic-regression"><i class="fa fa-check"></i><b>30.4</b> Example Logistic Regression</a></li>
<li class="chapter" data-level="30.5" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#example-poisson-regression"><i class="fa fa-check"></i><b>30.5</b> Example Poisson Regression</a></li>
<li class="chapter" data-level="30.6" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#about-variances"><i class="fa fa-check"></i><b>30.6</b> About Variances</a></li>
<li class="chapter" data-level="30.7" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#details"><i class="fa fa-check"></i><b>30.7</b> Details</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html"><i class="fa fa-check"></i><b>31</b> GLMs for Binary Data</a><ul>
<li class="chapter" data-level="31.1" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html#key-ideas-1"><i class="fa fa-check"></i><b>31.1</b> Key Ideas</a></li>
<li class="chapter" data-level="31.2" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html#ravens-data"><i class="fa fa-check"></i><b>31.2</b> Ravens Data</a></li>
<li class="chapter" data-level="31.3" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html#interpreting-logistic-regression"><i class="fa fa-check"></i><b>31.3</b> Interpreting Logistic Regression</a></li>
<li class="chapter" data-level="31.4" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html#making-the-model-in-r"><i class="fa fa-check"></i><b>31.4</b> Making the Model in R</a></li>
<li class="chapter" data-level="31.5" data-path="glms-for-binary-data.html"><a href="glms-for-binary-data.html#interpreting-odds-ratios"><i class="fa fa-check"></i><b>31.5</b> Interpreting Odds Ratios</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="poisson-glms.html"><a href="poisson-glms.html"><i class="fa fa-check"></i><b>32</b> Poisson GLMs</a><ul>
<li class="chapter" data-level="32.1" data-path="poisson-glms.html"><a href="poisson-glms.html#posison-distribution"><i class="fa fa-check"></i><b>32.1</b> Posison Distribution</a></li>
<li class="chapter" data-level="32.2" data-path="poisson-glms.html"><a href="poisson-glms.html#poisson-mass-function"><i class="fa fa-check"></i><b>32.2</b> Poisson Mass Function</a></li>
<li class="chapter" data-level="32.3" data-path="poisson-glms.html"><a href="poisson-glms.html#linear-regression"><i class="fa fa-check"></i><b>32.3</b> Linear regression</a></li>
<li class="chapter" data-level="32.4" data-path="poisson-glms.html"><a href="poisson-glms.html#exponentiating-coefficients"><i class="fa fa-check"></i><b>32.4</b> Exponentiating Coefficients</a></li>
<li class="chapter" data-level="32.5" data-path="poisson-glms.html"><a href="poisson-glms.html#linear-vs-poisson"><i class="fa fa-check"></i><b>32.5</b> Linear vs Poisson</a><ul>
<li class="chapter" data-level="32.5.1" data-path="poisson-glms.html"><a href="poisson-glms.html#multiplicitive-differences"><i class="fa fa-check"></i><b>32.5.1</b> Multiplicitive Differences</a></li>
</ul></li>
<li class="chapter" data-level="32.6" data-path="poisson-glms.html"><a href="poisson-glms.html#rates"><i class="fa fa-check"></i><b>32.6</b> Rates</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="exam-4.html"><a href="exam-4.html"><i class="fa fa-check"></i><b>33</b> Exam 4:</a></li>
<li class="chapter" data-level="34" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>34</b> Introduction To Machine Learning</a></li>
<li class="chapter" data-level="35" data-path="prediction-motivation.html"><a href="prediction-motivation.html"><i class="fa fa-check"></i><b>35</b> Prediction Motivation</a><ul>
<li class="chapter" data-level="35.1" data-path="prediction-motivation.html"><a href="prediction-motivation.html#who-predicts"><i class="fa fa-check"></i><b>35.1</b> Who Predicts?</a></li>
<li class="chapter" data-level="35.2" data-path="prediction-motivation.html"><a href="prediction-motivation.html#what-is-prediction"><i class="fa fa-check"></i><b>35.2</b> What is Prediction?</a></li>
<li class="chapter" data-level="35.3" data-path="prediction-motivation.html"><a href="prediction-motivation.html#components-of-a-predictor"><i class="fa fa-check"></i><b>35.3</b> Components of a Predictor</a><ul>
<li class="chapter" data-level="35.3.1" data-path="prediction-motivation.html"><a href="prediction-motivation.html#spam-example"><i class="fa fa-check"></i><b>35.3.1</b> SPAM example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="relative-importance-of-steps.html"><a href="relative-importance-of-steps.html"><i class="fa fa-check"></i><b>36</b> Relative importance of steps</a><ul>
<li class="chapter" data-level="36.1" data-path="relative-importance-of-steps.html"><a href="relative-importance-of-steps.html#features-matter"><i class="fa fa-check"></i><b>36.1</b> Features Matter</a><ul>
<li class="chapter" data-level="36.1.1" data-path="relative-importance-of-steps.html"><a href="relative-importance-of-steps.html#issues-to-consider"><i class="fa fa-check"></i><b>36.1.1</b> Issues to consider</a></li>
<li class="chapter" data-level="36.1.2" data-path="relative-importance-of-steps.html"><a href="relative-importance-of-steps.html#prediction-is-about-accuracy-trade-offs"><i class="fa fa-check"></i><b>36.1.2</b> Prediction is about accuracy trade-offs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="in-and-out-of-sample-error.html"><a href="in-and-out-of-sample-error.html"><i class="fa fa-check"></i><b>37</b> In and out of sample error</a><ul>
<li class="chapter" data-level="37.0.1" data-path="in-and-out-of-sample-error.html"><a href="in-and-out-of-sample-error.html#whats-going-on"><i class="fa fa-check"></i><b>37.0.1</b> What’s going on?</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="prediction-study-design.html"><a href="prediction-study-design.html"><i class="fa fa-check"></i><b>38</b> Prediction Study Design</a><ul>
<li class="chapter" data-level="38.1" data-path="prediction-study-design.html"><a href="prediction-study-design.html#avoid-small-sample-sizes"><i class="fa fa-check"></i><b>38.1</b> Avoid Small Sample Sizes</a></li>
<li class="chapter" data-level="38.2" data-path="prediction-study-design.html"><a href="prediction-study-design.html#rules-of-thumb-for-prediction-study-design"><i class="fa fa-check"></i><b>38.2</b> Rules of thumb for prediction study design</a></li>
<li class="chapter" data-level="38.3" data-path="prediction-study-design.html"><a href="prediction-study-design.html#some-principals-to-remember"><i class="fa fa-check"></i><b>38.3</b> Some Principals to Remember</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="types-of-errors.html"><a href="types-of-errors.html"><i class="fa fa-check"></i><b>39</b> Types of Errors</a><ul>
<li class="chapter" data-level="39.1" data-path="types-of-errors.html"><a href="types-of-errors.html#basic-terms"><i class="fa fa-check"></i><b>39.1</b> Basic Terms</a></li>
<li class="chapter" data-level="39.2" data-path="types-of-errors.html"><a href="types-of-errors.html#screening-tests"><i class="fa fa-check"></i><b>39.2</b> Screening Tests</a></li>
<li class="chapter" data-level="39.3" data-path="types-of-errors.html"><a href="types-of-errors.html#common-error-measures-for-continuous-data"><i class="fa fa-check"></i><b>39.3</b> Common Error Measures For Continuous Data</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="roc-curves.html"><a href="roc-curves.html"><i class="fa fa-check"></i><b>40</b> ROC Curves</a><ul>
<li class="chapter" data-level="40.1" data-path="roc-curves.html"><a href="roc-curves.html#why-a-curve"><i class="fa fa-check"></i><b>40.1</b> Why a Curve?</a></li>
<li class="chapter" data-level="40.2" data-path="roc-curves.html"><a href="roc-curves.html#cross-validation"><i class="fa fa-check"></i><b>40.2</b> Cross Validation</a><ul>
<li class="chapter" data-level="40.2.1" data-path="roc-curves.html"><a href="roc-curves.html#key-idea"><i class="fa fa-check"></i><b>40.2.1</b> Key Idea</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="roc-curves.html"><a href="roc-curves.html#example-14"><i class="fa fa-check"></i><b>40.3</b> Example:</a></li>
<li class="chapter" data-level="40.4" data-path="roc-curves.html"><a href="roc-curves.html#considerations"><i class="fa fa-check"></i><b>40.4</b> Considerations</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="what-data-should-you-use.html"><a href="what-data-should-you-use.html"><i class="fa fa-check"></i><b>41</b> What Data Should You Use?</a></li>
<li class="chapter" data-level="42" data-path="the-caret-package.html"><a href="the-caret-package.html"><i class="fa fa-check"></i><b>42</b> The Caret Package</a><ul>
<li class="chapter" data-level="42.1" data-path="the-caret-package.html"><a href="the-caret-package.html#machine-learning-algorithms-in-r"><i class="fa fa-check"></i><b>42.1</b> Machine Learning Algorithms in R</a></li>
<li class="chapter" data-level="42.2" data-path="the-caret-package.html"><a href="the-caret-package.html#spam-example-data-splitting"><i class="fa fa-check"></i><b>42.2</b> SPAM Example: Data Splitting</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="data-slicing.html"><a href="data-slicing.html"><i class="fa fa-check"></i><b>43</b> Data Slicing</a><ul>
<li class="chapter" data-level="43.1" data-path="data-slicing.html"><a href="data-slicing.html#spam-example-k-fold"><i class="fa fa-check"></i><b>43.1</b> SPAM Example: K-Fold</a></li>
<li class="chapter" data-level="43.2" data-path="data-slicing.html"><a href="data-slicing.html#spam-example-resampling"><i class="fa fa-check"></i><b>43.2</b> Spam Example: Resampling</a></li>
<li class="chapter" data-level="43.3" data-path="data-slicing.html"><a href="data-slicing.html#spam-example-time-slices"><i class="fa fa-check"></i><b>43.3</b> SPAM Example: Time Slices</a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="training-options.html"><a href="training-options.html"><i class="fa fa-check"></i><b>44</b> Training Options</a><ul>
<li class="chapter" data-level="44.1" data-path="training-options.html"><a href="training-options.html#traincontrol-resampling"><i class="fa fa-check"></i><b>44.1</b> trainControl Resampling</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="plotting-predictors.html"><a href="plotting-predictors.html"><i class="fa fa-check"></i><b>45</b> Plotting Predictors</a><ul>
<li class="chapter" data-level="45.1" data-path="plotting-predictors.html"><a href="plotting-predictors.html#making-factors-with-the-hmisc-package"><i class="fa fa-check"></i><b>45.1</b> Making Factors with the <code>Hmisc</code> package</a><ul>
<li class="chapter" data-level="45.1.1" data-path="plotting-predictors.html"><a href="plotting-predictors.html#making-tables"><i class="fa fa-check"></i><b>45.1.1</b> Making Tables</a></li>
<li class="chapter" data-level="45.1.2" data-path="plotting-predictors.html"><a href="plotting-predictors.html#density-plots"><i class="fa fa-check"></i><b>45.1.2</b> Density Plots</a></li>
</ul></li>
<li class="chapter" data-level="45.2" data-path="plotting-predictors.html"><a href="plotting-predictors.html#notes-3"><i class="fa fa-check"></i><b>45.2</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>46</b> Preprocessing</a><ul>
<li class="chapter" data-level="46.1" data-path="preprocessing.html"><a href="preprocessing.html#why-preprocess"><i class="fa fa-check"></i><b>46.1</b> Why Preprocess?</a></li>
<li class="chapter" data-level="46.2" data-path="preprocessing.html"><a href="preprocessing.html#standardising"><i class="fa fa-check"></i><b>46.2</b> Standardising</a><ul>
<li class="chapter" data-level="46.2.1" data-path="preprocessing.html"><a href="preprocessing.html#using-the-preprocess-function"><i class="fa fa-check"></i><b>46.2.1</b> Using the preProcess function</a></li>
</ul></li>
<li class="chapter" data-level="46.3" data-path="preprocessing.html"><a href="preprocessing.html#standardising-box-cox-transforms"><i class="fa fa-check"></i><b>46.3</b> Standardising: Box-Cox Transforms</a></li>
<li class="chapter" data-level="46.4" data-path="preprocessing.html"><a href="preprocessing.html#standardising-imputing-data"><i class="fa fa-check"></i><b>46.4</b> Standardising: Imputing Data</a></li>
</ul></li>
<li class="chapter" data-level="47" data-path="covariate-creation.html"><a href="covariate-creation.html"><i class="fa fa-check"></i><b>47</b> Covariate Creation</a><ul>
<li class="chapter" data-level="47.1" data-path="covariate-creation.html"><a href="covariate-creation.html#two-levels-of-covariate-creation"><i class="fa fa-check"></i><b>47.1</b> Two Levels of Covariate Creation</a></li>
<li class="chapter" data-level="47.2" data-path="covariate-creation.html"><a href="covariate-creation.html#removing-zero-covariates"><i class="fa fa-check"></i><b>47.2</b> Removing Zero Covariates</a></li>
<li class="chapter" data-level="47.3" data-path="covariate-creation.html"><a href="covariate-creation.html#spline-basis"><i class="fa fa-check"></i><b>47.3</b> Spline Basis</a></li>
<li class="chapter" data-level="47.4" data-path="covariate-creation.html"><a href="covariate-creation.html#notes-4"><i class="fa fa-check"></i><b>47.4</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html"><i class="fa fa-check"></i><b>48</b> Preprocessing With Principal Components Analysis (PCA)</a><ul>
<li class="chapter" data-level="48.1" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#basic-pca-idea"><i class="fa fa-check"></i><b>48.1</b> Basic PCA Idea</a></li>
<li class="chapter" data-level="48.2" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#two-related-problems"><i class="fa fa-check"></i><b>48.2</b> Two Related Problems</a></li>
<li class="chapter" data-level="48.3" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#single-value-decomposition-svd-and-principal-components-analysis-pca"><i class="fa fa-check"></i><b>48.3</b> Single Value Decomposition (SVD) and Principal Components Analysis (PCA)</a></li>
<li class="chapter" data-level="48.4" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#principal-components-in-r-prcomp"><i class="fa fa-check"></i><b>48.4</b> Principal Components in R <code>prComp</code></a></li>
<li class="chapter" data-level="48.5" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#pca-on-all-spam-data"><i class="fa fa-check"></i><b>48.5</b> PCA on All Spam Data</a></li>
<li class="chapter" data-level="48.6" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#pca-with-caret"><i class="fa fa-check"></i><b>48.6</b> PCA with Caret</a><ul>
<li class="chapter" data-level="48.6.1" data-path="preprocessing-with-principal-components-analysis-pca.html"><a href="preprocessing-with-principal-components-analysis-pca.html#preprocessing-with-pca"><i class="fa fa-check"></i><b>48.6.1</b> Preprocessing with PCA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html"><i class="fa fa-check"></i><b>49</b> Predicting with Regression</a><ul>
<li class="chapter" data-level="49.1" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#key-ideas-2"><i class="fa fa-check"></i><b>49.1</b> Key Ideas</a></li>
<li class="chapter" data-level="49.2" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#example-geyser-eruptions"><i class="fa fa-check"></i><b>49.2</b> Example: Geyser Eruptions</a></li>
<li class="chapter" data-level="49.3" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#predicting-a-new-value"><i class="fa fa-check"></i><b>49.3</b> Predicting a New Value</a></li>
<li class="chapter" data-level="49.4" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#plot-predictions-training-vs-test-set"><i class="fa fa-check"></i><b>49.4</b> Plot Predictions: Training vs Test Set</a></li>
<li class="chapter" data-level="49.5" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#get-training-and-test-set-errors"><i class="fa fa-check"></i><b>49.5</b> Get Training and Test set Errors</a></li>
<li class="chapter" data-level="49.6" data-path="predicting-with-regression.html"><a href="predicting-with-regression.html#prediction-intervals"><i class="fa fa-check"></i><b>49.6</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="predicting-with-regression-multiple-covariates.html"><a href="predicting-with-regression-multiple-covariates.html"><i class="fa fa-check"></i><b>50</b> Predicting with Regression Multiple Covariates</a><ul>
<li class="chapter" data-level="50.1" data-path="predicting-with-regression-multiple-covariates.html"><a href="predicting-with-regression-multiple-covariates.html#example-predicting-wages"><i class="fa fa-check"></i><b>50.1</b> Example: Predicting wages</a></li>
<li class="chapter" data-level="50.2" data-path="predicting-with-regression-multiple-covariates.html"><a href="predicting-with-regression-multiple-covariates.html#fit-a-linear-model"><i class="fa fa-check"></i><b>50.2</b> Fit a Linear Model</a></li>
<li class="chapter" data-level="50.3" data-path="predicting-with-regression-multiple-covariates.html"><a href="predicting-with-regression-multiple-covariates.html#eda-in-glms"><i class="fa fa-check"></i><b>50.3</b> EDA in GLMs</a></li>
<li class="chapter" data-level="50.4" data-path="predicting-with-regression-multiple-covariates.html"><a href="predicting-with-regression-multiple-covariates.html#predicted-vs-truth-in-test-set"><i class="fa fa-check"></i><b>50.4</b> Predicted vs Truth in Test Set</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html"><i class="fa fa-check"></i><b>51</b> Predicting with Trees</a><ul>
<li class="chapter" data-level="51.1" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html#key-ideas-3"><i class="fa fa-check"></i><b>51.1</b> Key Ideas</a></li>
<li class="chapter" data-level="51.2" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html#the-basic-algorithm"><i class="fa fa-check"></i><b>51.2</b> The Basic Algorithm</a></li>
<li class="chapter" data-level="51.3" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html#measures-of-impurity"><i class="fa fa-check"></i><b>51.3</b> Measures of Impurity</a></li>
<li class="chapter" data-level="51.4" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html#example-iris-data"><i class="fa fa-check"></i><b>51.4</b> Example: Iris Data</a></li>
<li class="chapter" data-level="51.5" data-path="predicting-with-trees.html"><a href="predicting-with-trees.html#notes-5"><i class="fa fa-check"></i><b>51.5</b> Notes:</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="bootstrap-aggregating-bagging.html"><a href="bootstrap-aggregating-bagging.html"><i class="fa fa-check"></i><b>52</b> Bootstrap Aggregating (Bagging)</a><ul>
<li class="chapter" data-level="52.1" data-path="bootstrap-aggregating-bagging.html"><a href="bootstrap-aggregating-bagging.html#example-using-bagged-loess"><i class="fa fa-check"></i><b>52.1</b> Example using Bagged Loess</a></li>
<li class="chapter" data-level="52.2" data-path="bootstrap-aggregating-bagging.html"><a href="bootstrap-aggregating-bagging.html#bagging-in-caret"><i class="fa fa-check"></i><b>52.2</b> Bagging in Caret</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>53</b> Random Forests</a><ul>
<li class="chapter" data-level="53.1" data-path="random-forests.html"><a href="random-forests.html#random-forest-example-with-the-iris-dataset"><i class="fa fa-check"></i><b>53.1</b> Random Forest Example With the Iris Dataset</a></li>
<li class="chapter" data-level="53.2" data-path="random-forests.html"><a href="random-forests.html#class-centers"><i class="fa fa-check"></i><b>53.2</b> Class “Centers”</a></li>
<li class="chapter" data-level="53.3" data-path="random-forests.html"><a href="random-forests.html#predicting-new-values"><i class="fa fa-check"></i><b>53.3</b> Predicting New Values</a></li>
<li class="chapter" data-level="53.4" data-path="random-forests.html"><a href="random-forests.html#notes-6"><i class="fa fa-check"></i><b>53.4</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="54" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>54</b> Boosting</a><ul>
<li class="chapter" data-level="54.1" data-path="boosting.html"><a href="boosting.html#basic-idea"><i class="fa fa-check"></i><b>54.1</b> Basic Idea</a></li>
<li class="chapter" data-level="54.2" data-path="boosting.html"><a href="boosting.html#boosting-in-r"><i class="fa fa-check"></i><b>54.2</b> Boosting in R</a></li>
<li class="chapter" data-level="54.3" data-path="boosting.html"><a href="boosting.html#wage-example"><i class="fa fa-check"></i><b>54.3</b> Wage Example</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="model-based-prediction.html"><a href="model-based-prediction.html"><i class="fa fa-check"></i><b>55</b> Model Based Prediction</a><ul>
<li class="chapter" data-level="55.1" data-path="model-based-prediction.html"><a href="model-based-prediction.html#basic-idea-1"><i class="fa fa-check"></i><b>55.1</b> Basic Idea</a></li>
<li class="chapter" data-level="55.2" data-path="model-based-prediction.html"><a href="model-based-prediction.html#model-based-approach"><i class="fa fa-check"></i><b>55.2</b> Model Based Approach</a></li>
<li class="chapter" data-level="55.3" data-path="model-based-prediction.html"><a href="model-based-prediction.html#classifying-using-the-model"><i class="fa fa-check"></i><b>55.3</b> Classifying Using the Model</a></li>
<li class="chapter" data-level="55.4" data-path="model-based-prediction.html"><a href="model-based-prediction.html#why-linear-discriminant-analysis"><i class="fa fa-check"></i><b>55.4</b> Why Linear Discriminant Analysis?</a></li>
<li class="chapter" data-level="55.5" data-path="model-based-prediction.html"><a href="model-based-prediction.html#decision-boundaries"><i class="fa fa-check"></i><b>55.5</b> Decision Boundaries</a></li>
<li class="chapter" data-level="55.6" data-path="model-based-prediction.html"><a href="model-based-prediction.html#discriminant-function"><i class="fa fa-check"></i><b>55.6</b> Discriminant Function</a></li>
<li class="chapter" data-level="55.7" data-path="model-based-prediction.html"><a href="model-based-prediction.html#naive-bayes"><i class="fa fa-check"></i><b>55.7</b> Naive Bayes</a></li>
<li class="chapter" data-level="55.8" data-path="model-based-prediction.html"><a href="model-based-prediction.html#example-iris-data-1"><i class="fa fa-check"></i><b>55.8</b> Example: Iris Data</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="regularised-regression.html"><a href="regularised-regression.html"><i class="fa fa-check"></i><b>56</b> Regularised Regression</a><ul>
<li class="chapter" data-level="56.1" data-path="regularised-regression.html"><a href="regularised-regression.html#basic-idea-2"><i class="fa fa-check"></i><b>56.1</b> Basic Idea</a></li>
<li class="chapter" data-level="56.2" data-path="regularised-regression.html"><a href="regularised-regression.html#a-motivating-example"><i class="fa fa-check"></i><b>56.2</b> A Motivating Example</a></li>
<li class="chapter" data-level="56.3" data-path="regularised-regression.html"><a href="regularised-regression.html#common-pattern"><i class="fa fa-check"></i><b>56.3</b> Common Pattern</a></li>
<li class="chapter" data-level="56.4" data-path="regularised-regression.html"><a href="regularised-regression.html#model-selection-approach-split-samples"><i class="fa fa-check"></i><b>56.4</b> Model Selection Approach: Split Samples</a></li>
<li class="chapter" data-level="56.5" data-path="regularised-regression.html"><a href="regularised-regression.html#decomposing-expected-prediction-error"><i class="fa fa-check"></i><b>56.5</b> Decomposing Expected Prediction Error</a></li>
<li class="chapter" data-level="56.6" data-path="regularised-regression.html"><a href="regularised-regression.html#another-issue-for-high-dimensional-data"><i class="fa fa-check"></i><b>56.6</b> Another Issue for High-Dimensional Data</a></li>
<li class="chapter" data-level="56.7" data-path="regularised-regression.html"><a href="regularised-regression.html#hard-thresholding"><i class="fa fa-check"></i><b>56.7</b> Hard Thresholding</a></li>
<li class="chapter" data-level="56.8" data-path="regularised-regression.html"><a href="regularised-regression.html#regularisation-for-regression"><i class="fa fa-check"></i><b>56.8</b> Regularisation for Regression</a></li>
<li class="chapter" data-level="56.9" data-path="regularised-regression.html"><a href="regularised-regression.html#ridge-regression"><i class="fa fa-check"></i><b>56.9</b> Ridge Regression</a><ul>
<li class="chapter" data-level="56.9.1" data-path="regularised-regression.html"><a href="regularised-regression.html#tuning-parameter-lambda"><i class="fa fa-check"></i><b>56.9.1</b> Tuning Parameter <span class="math inline">\(\lambda\)</span></a></li>
<li class="chapter" data-level="56.9.2" data-path="regularised-regression.html"><a href="regularised-regression.html#lasso"><i class="fa fa-check"></i><b>56.9.2</b> Lasso</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="57" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html"><i class="fa fa-check"></i><b>57</b> Combining Predictors (Ensembling Methods)</a><ul>
<li class="chapter" data-level="57.1" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html#key-ideas-4"><i class="fa fa-check"></i><b>57.1</b> Key Ideas</a><ul>
<li class="chapter" data-level="57.1.1" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html#basic-intuition---majority-vote"><i class="fa fa-check"></i><b>57.1.1</b> Basic Intuition - Majority Vote</a></li>
</ul></li>
<li class="chapter" data-level="57.2" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html#approaches-for-combining-classifiers"><i class="fa fa-check"></i><b>57.2</b> Approaches for Combining Classifiers</a></li>
<li class="chapter" data-level="57.3" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html#example-with-wage-data"><i class="fa fa-check"></i><b>57.3</b> Example with Wage Data</a></li>
<li class="chapter" data-level="57.4" data-path="combining-predictors-ensembling-methods.html"><a href="combining-predictors-ensembling-methods.html#notes-7"><i class="fa fa-check"></i><b>57.4</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="58" data-path="forecasting.html"><a href="forecasting.html"><i class="fa fa-check"></i><b>58</b> Forecasting</a><ul>
<li class="chapter" data-level="58.1" data-path="forecasting.html"><a href="forecasting.html#google-data-quantmod"><i class="fa fa-check"></i><b>58.1</b> Google Data: QuantMod</a></li>
<li class="chapter" data-level="58.2" data-path="forecasting.html"><a href="forecasting.html#example-time-series-decomposition"><i class="fa fa-check"></i><b>58.2</b> Example Time Series Decomposition</a></li>
<li class="chapter" data-level="58.3" data-path="forecasting.html"><a href="forecasting.html#training-and-test-sets"><i class="fa fa-check"></i><b>58.3</b> Training and Test Sets</a></li>
<li class="chapter" data-level="58.4" data-path="forecasting.html"><a href="forecasting.html#simple-moving-average"><i class="fa fa-check"></i><b>58.4</b> Simple Moving Average</a></li>
<li class="chapter" data-level="58.5" data-path="forecasting.html"><a href="forecasting.html#exponential-smoothing"><i class="fa fa-check"></i><b>58.5</b> Exponential Smoothing</a></li>
<li class="chapter" data-level="58.6" data-path="forecasting.html"><a href="forecasting.html#notes-8"><i class="fa fa-check"></i><b>58.6</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="59" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html"><i class="fa fa-check"></i><b>59</b> Unsupervised Prediction</a><ul>
<li class="chapter" data-level="59.1" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html#key-ideas-5"><i class="fa fa-check"></i><b>59.1</b> Key Ideas</a></li>
<li class="chapter" data-level="59.2" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html#irirs-example-ignoring-species-labels"><i class="fa fa-check"></i><b>59.2</b> Irirs Example Ignoring Species Labels</a><ul>
<li class="chapter" data-level="59.2.1" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html#build-a-predictor"><i class="fa fa-check"></i><b>59.2.1</b> Build a Predictor</a></li>
<li class="chapter" data-level="59.2.2" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html#apply-on-the-test-data-set"><i class="fa fa-check"></i><b>59.2.2</b> Apply on the Test Data Set</a></li>
</ul></li>
<li class="chapter" data-level="59.3" data-path="unsupervised-prediction.html"><a href="unsupervised-prediction.html#notes-9"><i class="fa fa-check"></i><b>59.3</b> Notes</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analysis Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-linear-regression-models" class="section level1">
<h1><span class="header-section-number">20</span> Statistical Linear Regression Models</h1>
<blockquote>
<p>Up to this point, we’ve only considered estimation. Estimation is useful, but we also need to know how to extend our estimates to a population. This is the process of statistical inference. Our approach to statistical inference will be through a statistical model. At the bare minimum, we need a few distributional assumptions on the errors. However, we’ll focus on full model assumptions under Gaussianity.</p>
</blockquote>
<div id="basic-regression-model-with-additive-gaussian-errors" class="section level2">
<h2><span class="header-section-number">20.1</span> Basic Regression Model with Additive Gaussian Errors</h2>
<p>We would like to generalise to a population, using our data and some statistical analysis.</p>
<ul>
<li>Least squares is an estimation tool, how do we inference?</li>
<li>Consider developing a probabalistic model for linear regression.</li>
</ul>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\]</span></p>
<ul>
<li>Here the independant gaussian errors <span class="math inline">\(\epsilon_i\)</span> are assumed to be normally distributed <span class="math inline">\(N(0, \sigma^2)\)</span></li>
<li>Note, <span class="math inline">\(E[Y_i | X_i = x_i] = \mu_i = \beta_0 + \beta_1 x_i\)</span></li>
<li>Note, <span class="math inline">\(Var(Y_i|X_i = x_i) = \sigma^2\)</span></li>
</ul>
</div>
<div id="interpreting-coefficients" class="section level2">
<h2><span class="header-section-number">20.2</span> Interpreting Coefficients</h2>
<p>Now that we have a formal statistical framework, we can interpret our regression coefficients with respect to that framework.</p>
<p><span class="math inline">\(\beta_1\)</span> is the expected change in response for a 1 unit change in the predictor.
<span class="math display">\[E[Y | X = x +1] - E[Y | X = x] = \beta_0 + \beta_1(x+1) - (\beta_0 + \beta_1 x) = \beta_1\]</span></p>
</div>
<div id="linear-regression-for-prediction" class="section level2">
<h2><span class="header-section-number">20.3</span> Linear Regression for Prediction</h2>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" title="1"><span class="kw">data</span>(diamond)</a>
<a class="sourceLine" id="cb133-2" title="2"></a>
<a class="sourceLine" id="cb133-3" title="3">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(diamond, <span class="kw">aes</span>( <span class="dt">x =</span> carat, <span class="dt">y =</span> price))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb133-4" title="4"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mass (carats)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb133-5" title="5"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Price (SIN $)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb133-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb133-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb133-8" title="8"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb133-9" title="9"></a>
<a class="sourceLine" id="cb133-10" title="10">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Gitbook1_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<div id="fitting-the-linear-regression-model" class="section level3">
<h3><span class="header-section-number">20.3.1</span> Fitting the Linear Regression Model</h3>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" title="1">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>carat, <span class="dt">data =</span> diamond)</a>
<a class="sourceLine" id="cb135-2" title="2"><span class="kw">coef</span>(fit)</a></code></pre></div>
<pre><code>## (Intercept)       carat 
##   -259.6259   3721.0249</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" title="1"><span class="kw">summary</span>(fit)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ carat, data = diamond)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -85.159 -21.448  -0.869  18.972  79.370 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -259.63      17.32  -14.99   &lt;2e-16 ***
## carat        3721.02      81.79   45.50   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31.84 on 46 degrees of freedom
## Multiple R-squared:  0.9783, Adjusted R-squared:  0.9778 
## F-statistic:  2070 on 1 and 46 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>We therefore estimate an expected 3721.02 (SIN $) for every carat increase in mass of diamond.</li>
</ul>
</div>
<div id="getting-a-more-interpretable-result" class="section level3">
<h3><span class="header-section-number">20.3.2</span> Getting a More Interpretable Result</h3>
<p>Here, we’ll <strong>mean-centre</strong> our predictor variable, carat.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb139-1" title="1">fit2 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(carat <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(carat)), <span class="dt">data =</span> diamond)</a>
<a class="sourceLine" id="cb139-2" title="2"><span class="kw">coef</span>(fit2)</a></code></pre></div>
<pre><code>##            (Intercept) I(carat - mean(carat)) 
##               500.0833              3721.0249</code></pre>
<p>Here we can see that the slope <span class="math inline">\(\beta_1\)</span>is the same as before, only the intercept <span class="math inline">\(\beta_0\)</span> is different. We can interpret this result as <strong>The expected price for the average sized diamond (0.2042 carats) from our data is $500.1 SIN</strong></p>
<p>What if we waned to know what the price increase would be from a 1/10 increase in carat? A 1 carat increase in mass is fairly large.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" title="1">fit3 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(carat <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">data =</span> diamond)</a>
<a class="sourceLine" id="cb141-2" title="2"><span class="kw">coef</span>(fit3)</a></code></pre></div>
<pre><code>##   (Intercept) I(carat * 10) 
##     -259.6259      372.1025</code></pre>
</div>
<div id="predicting-the-price-of-a-diamond" class="section level3">
<h3><span class="header-section-number">20.3.3</span> Predicting the Price of a Diamond</h3>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" title="1"><span class="co"># New mass of diamond we want to predict</span></a>
<a class="sourceLine" id="cb143-2" title="2">newx &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.16</span>, <span class="fl">0.27</span>, <span class="fl">0.34</span>)</a>
<a class="sourceLine" id="cb143-3" title="3"></a>
<a class="sourceLine" id="cb143-4" title="4"><span class="co"># Following the form of our regression equation we can just insert the new diamond data to predict their price using the regression model we fit on our previous data</span></a>
<a class="sourceLine" id="cb143-5" title="5"><span class="kw">coef</span>(fit)[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(fit)[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>newx</a></code></pre></div>
<pre><code>## [1]  335.7381  745.0508 1005.5225</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" title="1"><span class="co"># This can also be done with the `predict` function</span></a>
<a class="sourceLine" id="cb145-2" title="2"><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">carat =</span> newx))</a></code></pre></div>
<pre><code>##         1         2         3 
##  335.7381  745.0508 1005.5225</code></pre>
</div>
</div>
<div id="residuals-and-residual-variation" class="section level2">
<h2><span class="header-section-number">20.4</span> Residuals and Residual Variation</h2>
<blockquote>
<p><strong>Residuals represent variation left unexplained by our model.</strong> We emphasize the difference between residuals and errors. The errors unobservable true errors from the known coefficients, while residuals are the observable errors from the estimated coefficients. In a sense, the residuals are estimates of the errors.</p>
</blockquote>
<div id="motivating-example" class="section level3">
<h3><span class="header-section-number">20.4.1</span> Motivating example</h3>
<p><code>diamond</code> data set from the <code>UsingR</code> package. Data is diamond prices (Singapore Dollars) and diamond weight in carats.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" title="1"><span class="kw">data</span>(diamond)</a>
<a class="sourceLine" id="cb147-2" title="2"></a>
<a class="sourceLine" id="cb147-3" title="3">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(diamond, <span class="kw">aes</span>( <span class="dt">x =</span> carat, <span class="dt">y =</span> price))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb147-4" title="4"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mass (carats)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb147-5" title="5"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Price (SIN $)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb147-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb147-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb147-8" title="8"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb147-9" title="9"></a>
<a class="sourceLine" id="cb147-10" title="10">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Gitbook1_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<ul>
<li>Our model is <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i ~ N(0, \sigma^2)\)</span></li>
<li>Observed outcome <span class="math inline">\(i\)</span> is <span class="math inline">\(Y_i\)</span> at predictor value <span class="math inline">\(X_i\)</span>.</li>
<li>Residual, between the observed and predicted outcome <span class="math inline">\(e_i = Y_i - \hat{Y_i}\)</span>.</li>
<li>The vertical distance between the observed data point and the regression line.</li>
<li>The <span class="math inline">\(e_i\)</span> can be thought of as estimates of the <span class="math inline">\(\epsilon_i\)</span>.</li>
</ul>
</div>
<div id="properties-of-the-residuals" class="section level3">
<h3><span class="header-section-number">20.4.2</span> Properties of the Residuals</h3>
<ul>
<li><span class="math inline">\(E[e_i] = 0\)</span></li>
<li>If an intercept is included, <span class="math inline">\(\sum_{i=1}^n e_i = 0\)</span></li>
<li>If a regressor variable, <span class="math inline">\(X_i\)</span> is included in the model <span class="math inline">\(\sum_{i=1}^n e_i X_i =0\)</span></li>
<li>Residuals are useful for investigating poor model fit.</li>
<li>Positive residuals are above the line, negative residuals are below.</li>
<li>Residuals can be thought of as the outcome <span class="math inline">\((Y)\)</span> with the linear association of the predictor <span class="math inline">\((X)\)</span> removed.</li>
</ul>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" title="1"><span class="co"># Load diamond data from UsingR package</span></a>
<a class="sourceLine" id="cb149-2" title="2"><span class="kw">data</span>(diamond)</a>
<a class="sourceLine" id="cb149-3" title="3"></a>
<a class="sourceLine" id="cb149-4" title="4"><span class="co"># Set variables are price and diamond mass</span></a>
<a class="sourceLine" id="cb149-5" title="5">y &lt;-<span class="st"> </span>diamond<span class="op">$</span>price </a>
<a class="sourceLine" id="cb149-6" title="6">x&lt;-<span class="st"> </span>diamond<span class="op">$</span>carat </a>
<a class="sourceLine" id="cb149-7" title="7">n &lt;-<span class="st"> </span><span class="kw">length</span>(y)</a>
<a class="sourceLine" id="cb149-8" title="8"></a>
<a class="sourceLine" id="cb149-9" title="9"><span class="co"># Create the linear model with the lm() function</span></a>
<a class="sourceLine" id="cb149-10" title="10">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb149-11" title="11"></a>
<a class="sourceLine" id="cb149-12" title="12"><span class="co"># Calculate the residuals from the linear model with the resid() function</span></a>
<a class="sourceLine" id="cb149-13" title="13">e &lt;-<span class="st"> </span><span class="kw">resid</span>(fit)</a>
<a class="sourceLine" id="cb149-14" title="14"></a>
<a class="sourceLine" id="cb149-15" title="15"><span class="co"># Calculate the predicted values (yhat) using the predict function</span></a>
<a class="sourceLine" id="cb149-16" title="16">yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit)</a>
<a class="sourceLine" id="cb149-17" title="17"></a>
<a class="sourceLine" id="cb149-18" title="18"><span class="kw">max</span>(<span class="kw">abs</span>(e <span class="op">-</span><span class="st"> </span>(y <span class="op">-</span><span class="st"> </span>yhat)))</a></code></pre></div>
<pre><code>## [1] 9.485746e-13</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" title="1"><span class="kw">max</span>(<span class="kw">abs</span>(e <span class="op">-</span><span class="st"> </span>(y <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(fit)[<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(fit)[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>x)))</a></code></pre></div>
<pre><code>## [1] 9.485746e-13</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" title="1"><span class="kw">sum</span>(e)</a></code></pre></div>
<pre><code>## [1] -1.865175e-14</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1"><span class="kw">sum</span>(e <span class="op">*</span><span class="st"> </span>x)</a></code></pre></div>
<pre><code>## [1] 6.959711e-15</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" title="1"><span class="co"># Lets plot the residuals on the standard linear plot</span></a>
<a class="sourceLine" id="cb157-2" title="2"><span class="kw">plot</span>(diamond<span class="op">$</span>carat, diamond<span class="op">$</span>price, </a>
<a class="sourceLine" id="cb157-3" title="3">     <span class="dt">xlab =</span> <span class="st">&quot;Mass (carats)&quot;</span>,</a>
<a class="sourceLine" id="cb157-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;Price (SIN $)&quot;</span>,</a>
<a class="sourceLine" id="cb157-5" title="5">     <span class="dt">bg =</span> <span class="st">&quot;lightblue&quot;</span>,</a>
<a class="sourceLine" id="cb157-6" title="6">     <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">cex =</span> <span class="fl">1.1</span>, <span class="dt">pch =</span> <span class="dv">21</span>, <span class="dt">frame =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb157-7" title="7"><span class="kw">abline</span>(fit, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb157-8" title="8"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)</a>
<a class="sourceLine" id="cb157-9" title="9">  <span class="kw">lines</span>(<span class="kw">c</span>(x[i], x[i]), <span class="kw">c</span>(y[i], yhat[i]), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="Gitbook1_files/figure-html/unnamed-chunk-49-1.png" width="672" />
This makes it quite hard to see the residuals as there is so much empty space on the plot, so this time, lets plot the residuals and the mass of the diamonds.</p>
<p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" title="1"><span class="kw">plot</span>(x, e,</a>
<a class="sourceLine" id="cb158-2" title="2">     <span class="dt">xlab =</span> <span class="st">&quot;Mass (carats)&quot;</span>,</a>
<a class="sourceLine" id="cb158-3" title="3">     <span class="dt">ylab =</span> <span class="st">&quot;Residuals (SIN $)&quot;</span>,</a>
<a class="sourceLine" id="cb158-4" title="4">     <span class="dt">bg =</span> <span class="st">&quot;lightblue&quot;</span>,</a>
<a class="sourceLine" id="cb158-5" title="5">     <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>, <span class="dt">pch =</span> <span class="dv">21</span>, <span class="dt">frame =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb158-6" title="6"><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb158-7" title="7"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)</a>
<a class="sourceLine" id="cb158-8" title="8">  <span class="kw">lines</span>(<span class="kw">c</span>(x[i], x[i]), <span class="kw">c</span>(e[i], <span class="dv">0</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span> ,<span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<img src="Gitbook1_files/figure-html/unnamed-chunk-50-1.png" width="672" />
</p>
<p>This plot makes it much easier to see the residual variation. With a plot like this, you must look for any pattern. <strong>The residuals should be patternless.</strong> Something we can see here for example, is that there have been many diamonds of the same mass measured. This information tends to get lost in the scatter plots.</p>
</div>
<div id="non-linear-data" class="section level3">
<h3><span class="header-section-number">20.4.3</span> Non Linear Data</h3>
<p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" title="1"><span class="co"># Create some non-linear data</span></a>
<a class="sourceLine" id="cb159-2" title="2">x =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dv">-3</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb159-3" title="3">y =<span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">sin</span>(x) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dt">sd =</span> <span class="fl">.2</span>)</a>
<a class="sourceLine" id="cb159-4" title="4"></a>
<a class="sourceLine" id="cb159-5" title="5"><span class="co"># Graph it</span></a>
<a class="sourceLine" id="cb159-6" title="6">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb159-7" title="7"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb159-8" title="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">7</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb159-9" title="9"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb159-10" title="10"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Non-Linear Data&quot;</span>)</a>
<a class="sourceLine" id="cb159-11" title="11"></a>
<a class="sourceLine" id="cb159-12" title="12">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Gitbook1_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" title="1"><span class="co"># Let&#39;s now make a plot of the Residuals vs the Mass</span></a>
<a class="sourceLine" id="cb161-2" title="2">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">resid</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x))), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb161-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb161-4" title="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">7</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb161-5" title="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb161-6" title="6"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Residual&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb161-7" title="7"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Non-Linear Data Residual Plot&quot;</span>)</a>
<a class="sourceLine" id="cb161-8" title="8"></a>
<a class="sourceLine" id="cb161-9" title="9">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<img src="Gitbook1_files/figure-html/unnamed-chunk-51-2.png" width="672" />
</p>
<p>This is now super obvious that the data isn’t linear, the sine wave becomes evident.</p>
</div>
<div id="heteroskedasticity" class="section level3">
<h3><span class="header-section-number">20.4.4</span> Heteroskedasticity</h3>
<p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="co"># Make some data with constantly increasing variance</span></a>
<a class="sourceLine" id="cb163-2" title="2">x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb163-3" title="3">y &lt;-<span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">.001</span> <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb163-4" title="4"></a>
<a class="sourceLine" id="cb163-5" title="5">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb163-6" title="6"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb163-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">7</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb163-8" title="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb163-9" title="9"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Heteroskedastic data plot&quot;</span>)</a>
<a class="sourceLine" id="cb163-10" title="10"></a>
<a class="sourceLine" id="cb163-11" title="11">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<img src="Gitbook1_files/figure-html/unnamed-chunk-52-1.png" width="672" />
</p>
<p>This looks like the data falls perfectly on the line right? Great linear model? Lets look at the residuals and find out…</p>
<p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" title="1">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">resid</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x))), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb165-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb165-3" title="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">7</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb165-4" title="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb165-5" title="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Heteroskedastic data plot&quot;</span>)</a>
<a class="sourceLine" id="cb165-6" title="6"></a>
<a class="sourceLine" id="cb165-7" title="7">g</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<img src="Gitbook1_files/figure-html/unnamed-chunk-53-1.png" width="672" />
</p>
<p>However, looking at the residuals, the variance is not constant throughout, this is evidence of our data not being linearly related. Residual plots are great at highlighing this.</p>
<p>Lets look again at the diamond residual data for any trends that we may have missed.</p>
<p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1">diamond<span class="op">$</span>e &lt;-<span class="st"> </span><span class="kw">resid</span>(<span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>carat, <span class="dt">data =</span> diamond))</a>
<a class="sourceLine" id="cb167-2" title="2"></a>
<a class="sourceLine" id="cb167-3" title="3">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(diamond, <span class="kw">aes</span>(<span class="dt">x =</span> carat, <span class="dt">y =</span> e)) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-4" title="4"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mass&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-5" title="5"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Price&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-6" title="6"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">7</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-8" title="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">siz =</span> <span class="dv">5</span>, <span class="dt">colour =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb167-9" title="9"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Diamond Residual Plot&quot;</span>)</a></code></pre></div>
<pre><code>## Warning: Ignoring unknown parameters: siz</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1">g</a></code></pre></div>
<img src="Gitbook1_files/figure-html/unnamed-chunk-54-1.png" width="672" />
</p>
<p>This seems like a really god fit, the residuals are seemingly randomly distributed.</p>
<p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" title="1"><span class="co"># create two residual vectors, one fits deviation around price, and one that uses the diamond mass as a predictor variable (variation around the regression line)</span></a>
<a class="sourceLine" id="cb170-2" title="2">e =<span class="kw">c</span>(<span class="kw">resid</span>(<span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> diamond)),</a>
<a class="sourceLine" id="cb170-3" title="3">     <span class="kw">resid</span>(<span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>carat, <span class="dt">data =</span> diamond)))</a>
<a class="sourceLine" id="cb170-4" title="4"></a>
<a class="sourceLine" id="cb170-5" title="5"><span class="co"># create a factor variable that labels the set of residuals</span></a>
<a class="sourceLine" id="cb170-6" title="6">fit =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;Intercept only&quot;</span>, <span class="kw">nrow</span>(diamond)), </a>
<a class="sourceLine" id="cb170-7" title="7">               <span class="kw">rep</span>(<span class="st">&quot;Itercept and slope&quot;</span>, <span class="kw">nrow</span>(diamond))))</a>
<a class="sourceLine" id="cb170-8" title="8"></a>
<a class="sourceLine" id="cb170-9" title="9">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">e =</span> e, <span class="dt">fit =</span> fit), <span class="kw">aes</span>( <span class="dt">y =</span> e, <span class="dt">x =</span> fit, <span class="dt">fill =</span> fit)) <span class="op">+</span></a>
<a class="sourceLine" id="cb170-10" title="10"><span class="st">  </span><span class="kw">geom_dotplot</span>(<span class="dt">binaxis =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">stackdir =</span> <span class="st">&quot;center&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb170-11" title="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Fitting approach&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb170-12" title="12"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Residual Price&quot;</span>)</a></code></pre></div>
<pre><code>## Warning: Ignoring unknown parameters: size</code></pre>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" title="1">g</a></code></pre></div>
<pre><code>## `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<img src="Gitbook1_files/figure-html/unnamed-chunk-55-1.png" width="672" />
</p>
</div>
</div>
<div id="estimating-residual-variation" class="section level2">
<h2><span class="header-section-number">20.5</span> Estimating Residual Variation</h2>
<p>Residual variation is variation around the regression line.</p>
<ul>
<li>Model <span class="math inline">\(Y_i = \beta_0, \beta_1 X_i + \epsilon_i\)</span> where <span class="math inline">\(\epsilon_i ~ N(0, \sigma^2)\)</span>.</li>
<li>The ML estimate of <span class="math inline">\(\sigma^2\)</span> is <span class="math inline">\({1 \over n} \sum_{i=1}^n e_i^2\)</span>, the average residual.</li>
<li>Most people use <span class="math inline">\(\hat{\sigma^2}={1 \over n-2} \sum_{i=1}^n e_i^2\)</span>.</li>
<li>The <span class="math inline">\(n-2\)</span> instead of <span class="math inline">\(n\)</span> is so that <span class="math inline">\(E[\hat{\sigma^2}] = \sigma^2\)</span></li>
</ul>
<p>Lets look at how to grab the residual variation out of our lm fit:</p>
<p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb174-1" title="1">y &lt;-<span class="st"> </span>diamond<span class="op">$</span>price</a>
<a class="sourceLine" id="cb174-2" title="2">x &lt;-<span class="st"> </span>diamond<span class="op">$</span>carat</a>
<a class="sourceLine" id="cb174-3" title="3">n &lt;-<span class="st"> </span><span class="kw">length</span>(y)</a>
<a class="sourceLine" id="cb174-4" title="4"></a>
<a class="sourceLine" id="cb174-5" title="5">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb174-6" title="6"></a>
<a class="sourceLine" id="cb174-7" title="7"><span class="kw">summary</span>(fit)<span class="op">$</span>sigma</a></code></pre></div>
<pre><code>## [1] 31.84052</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" title="1"><span class="kw">sqrt</span>(<span class="kw">sum</span>(<span class="kw">resid</span>(fit)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(n<span class="dv">-2</span>))</a></code></pre></div>
<pre><code>## [1] 31.84052</code></pre>
</p>
</div>
<div id="r-squared" class="section level2">
<h2><span class="header-section-number">20.6</span> R Squared</h2>
<p>R Squared is the percentage of the total variability that is explained by the linear relationship with the predictor.
<span class="math display">\[R^2 = {{\sum_{i=1}^n (\hat{Y_i} - \bar{Y})^2}\over{\sum_{i=1}^n (Y_i - \bar{Y}})^2}\]</span>
Where:</p>
<ul>
<li><span class="math inline">\(\sum_{i=1}^n (\hat{Y_i} - \bar{Y})^2\)</span> is the regression variation</li>
<li><span class="math inline">\(\sum_{i=1}^n (Y_i - \bar{Y})^2\)</span> is the total variation</li>
</ul>
<p><span class="math inline">\(R^2\)</span> is the percentage of variation explained by the regression model. <strong>(Also the correlation squared)</strong>
This metric cannot tell you if the it is right or not, it does not replace a simple scatter plot and must only be applied in the correct way, for example deleting data can inflate <span class="math inline">\(R^2\)</span>.</p>
<div id="example-13" class="section level3">
<h3><span class="header-section-number">20.6.1</span> Example:</h3>
<p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" title="1"><span class="kw">data</span>(<span class="st">&quot;anscombe&quot;</span>); <span class="kw">example</span>(<span class="st">&quot;anscombe&quot;</span>)</a></code></pre></div>
<pre><code>## 
## anscmb&gt; require(stats); require(graphics)
## 
## anscmb&gt; summary(anscombe)
##        x1             x2             x3             x4           y1        
##  Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  
##  1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  
##  Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  
##  Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  
##  3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  
##  Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  
##        y2              y3              y4        
##  Min.   :3.100   Min.   : 5.39   Min.   : 5.250  
##  1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  
##  Median :8.140   Median : 7.11   Median : 7.040  
##  Mean   :7.501   Mean   : 7.50   Mean   : 7.501  
##  3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  
##  Max.   :9.260   Max.   :12.74   Max.   :12.500  
## 
## anscmb&gt; ##-- now some &quot;magic&quot; to do the 4 regressions in a loop:
## anscmb&gt; ff &lt;- y ~ x
## 
## anscmb&gt; mods &lt;- setNames(as.list(1:4), paste0(&quot;lm&quot;, 1:4))
## 
## anscmb&gt; for(i in 1:4) {
## anscmb+   ff[2:3] &lt;- lapply(paste0(c(&quot;y&quot;,&quot;x&quot;), i), as.name)
## anscmb+   ## or   ff[[2]] &lt;- as.name(paste0(&quot;y&quot;, i))
## anscmb+   ##      ff[[3]] &lt;- as.name(paste0(&quot;x&quot;, i))
## anscmb+   mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)
## anscmb+   print(anova(lmi))
## anscmb+ }
## Analysis of Variance Table
## 
## Response: y1
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## x1         1 27.510 27.5100   17.99 0.00217 **
## Residuals  9 13.763  1.5292                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## Analysis of Variance Table
## 
## Response: y2
##           Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## x2         1 27.500 27.5000  17.966 0.002179 **
## Residuals  9 13.776  1.5307                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## Analysis of Variance Table
## 
## Response: y3
##           Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## x3         1 27.470 27.4700  17.972 0.002176 **
## Residuals  9 13.756  1.5285                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## Analysis of Variance Table
## 
## Response: y4
##           Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## x4         1 27.490 27.4900  18.003 0.002165 **
## Residuals  9 13.742  1.5269                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## anscmb&gt; ## See how close they are (numerically!)
## anscmb&gt; sapply(mods, coef)
##                   lm1      lm2       lm3       lm4
## (Intercept) 3.0000909 3.000909 3.0024545 3.0017273
## x1          0.5000909 0.500000 0.4997273 0.4999091
## 
## anscmb&gt; lapply(mods, function(fm) coef(summary(fm)))
## $lm1
##              Estimate Std. Error  t value    Pr(&gt;|t|)
## (Intercept) 3.0000909  1.1247468 2.667348 0.025734051
## x1          0.5000909  0.1179055 4.241455 0.002169629
## 
## $lm2
##             Estimate Std. Error  t value    Pr(&gt;|t|)
## (Intercept) 3.000909  1.1253024 2.666758 0.025758941
## x2          0.500000  0.1179637 4.238590 0.002178816
## 
## $lm3
##              Estimate Std. Error  t value    Pr(&gt;|t|)
## (Intercept) 3.0024545  1.1244812 2.670080 0.025619109
## x3          0.4997273  0.1178777 4.239372 0.002176305
## 
## $lm4
##              Estimate Std. Error  t value    Pr(&gt;|t|)
## (Intercept) 3.0017273  1.1239211 2.670763 0.025590425
## x4          0.4999091  0.1178189 4.243028 0.002164602
## 
## 
## anscmb&gt; ## Now, do what you should have done in the first place: PLOTS
## anscmb&gt; op &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))
## 
## anscmb&gt; for(i in 1:4) {
## anscmb+   ff[2:3] &lt;- lapply(paste0(c(&quot;y&quot;,&quot;x&quot;), i), as.name)
## anscmb+   plot(ff, data = anscombe, col = &quot;red&quot;, pch = 21, bg = &quot;orange&quot;, cex = 1.2,
## anscmb+        xlim = c(3, 19), ylim = c(3, 13))
## anscmb+   abline(mods[[i]], col = &quot;blue&quot;)
## anscmb+ }</code></pre>
<p><img src="Gitbook1_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre><code>## 
## anscmb&gt; mtext(&quot;Anscombe&#39;s 4 Regression data sets&quot;, outer = TRUE, cex = 1.5)
## 
## anscmb&gt; par(op)</code></pre>
</p>
<p>All of the following plots have identical <span class="math inline">\(R^2\)</span> values.</p>
<ul>
<li>The first plot is a fairly good linear plot, albeit with a lot of noise.</li>
<li>The second plot clearly shows that there is a missing term to address the curvature.</li>
<li>The third plot has an obvious outlier that need addressing.</li>
<li>The fourth plot has all of the data in one place with a single data point placed far off in the distance.</li>
</ul>
</div>
</div>
<div id="inference-in-regression" class="section level2">
<h2><span class="header-section-number">20.7</span> Inference in Regression</h2>
<blockquote>
<p>Inference is the process of drawing conclusions about a population using a sample. In statistical inference, we must account for the uncertainty in our estimates in a principled way. Hypothesis tests and confidence intervals are among the most common forms of statistical inference.</p>
</blockquote>
<ul>
<li>We assume that the true model is known.</li>
<li>The model: <span class="math display">\[Y_i = \beta_0, \beta_1 X_i + \epsilon_i\]</span> where <span class="math inline">\(\epsilon_i ~ N(0, \sigma^2)\)</span>.</li>
<li>The intercept: <span class="math display">\[\hat{\beta_0} = \bar{Y} - \hat{\beta_1} \bar{X}\]</span></li>
<li>The slope: <span class="math display">\[\hat{\beta_1} = Cor(Y,X){{Sd(Y)}\over{Sd(X)}}\]</span></li>
</ul>
<p>Statistics like <span class="math inline">\({\hat{\theta} - \theta}\over{\hat{\sigma_{\hat{\theta}}}}\)</span> generally have the following properties:</p>
<ul>
<li>They’re normally distributed</li>
<li>Can be used to create hypothesis tests such as <span class="math inline">\(H_0: \theta = \theta_0\)</span> versus <span class="math inline">\(H_A: \theta &gt;, &lt;, \ne \theta_0\)</span></li>
<li>Can be used to make conidence intervals for <span class="math inline">\(\theta\)</span> via the estimate plus or minus the relevant quantile multipled by the standard error <span class="math inline">\(\hat{\theta} \pm Q_{1- \alpha/2} \hat{\sigma_{\hat{\theta}}}\)</span>
<ul>
<li>where <span class="math inline">\(\hat{\theta}\)</span> is the estimate.</li>
<li><span class="math inline">\(Q_{1- \alpha/2}\)</span> is the relevent quantile from either a normal or T distribution. The alpha here depends on what you choose it to be, normally its 0.05.</li>
<li><span class="math inline">\(\hat{\sigma_{\hat{\theta}}}\)</span> is the standard error.</li>
</ul></li>
<li>In the case of regression with <strong>iid sampling and normal errors</strong>, our inferences will follow very similarly to what you saw in your inference class.</li>
</ul>
<p>The variance of our regression slope is a highly informative formula:</p>
<p><span class="math display">\[\sigma_{\hat{\beta_1}}^2 = Var(\hat{\beta_1}) = \sigma^2 / \sum_{i=1}^n (X_i - \bar{X})^2\]</span>
The variation around the slope (standard error) relies on two things:</p>
<ul>
<li>How variable the points are around the true regression line <span class="math inline">\(\sigma^2\)</span></li>
<li>How variable the <span class="math inline">\(X\)</span>s are.</li>
</ul>
<p>The variance of the intercept</p>
<p><span class="math display">\[\sigma_{\hat{\beta_0}}^2 = Var(\hat{\beta_0}) = ({1 \over n} + {{\bar{X^2}}\over{\sum_{i=1}^n (X_i - \bar{X})^2}}) \sigma^2\]</span></p>
<ul>
<li>In practice, <span class="math inline">\(\sigma\)</span> is replaced by its logical estimate (the sum of squared residuals).</li>
</ul>
<p><span class="math display">\[{\hat{\beta_j}- \beta_j}\over{\sigma_{\hat{\beta_j}}}\]</span></p>
<ul>
<li>Our slope or intercept estimate minus the true value divided by their standard error follows a T-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.</li>
<li>This can be usde to make confidence intervals and hypothesis tests.</li>
</ul>
<div id="hand-rolling-the-linear-regression-function" class="section level3">
<h3><span class="header-section-number">20.7.1</span> Hand-rolling the linear regression function</h3>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" title="1"><span class="co"># create variables using diamond data set</span></a>
<a class="sourceLine" id="cb181-2" title="2">y &lt;-<span class="st"> </span>diamond<span class="op">$</span>price</a>
<a class="sourceLine" id="cb181-3" title="3">x &lt;-<span class="st"> </span>diamond<span class="op">$</span>carat </a>
<a class="sourceLine" id="cb181-4" title="4">n &lt;-<span class="st"> </span><span class="kw">length</span>(y)</a>
<a class="sourceLine" id="cb181-5" title="5"></a>
<a class="sourceLine" id="cb181-6" title="6"><span class="co"># create regression coefficients</span></a>
<a class="sourceLine" id="cb181-7" title="7">beta1 &lt;-<span class="st"> </span><span class="kw">cor</span>(y,x) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sd</span>(x)</a>
<a class="sourceLine" id="cb181-8" title="8">beta0 &lt;-<span class="st"> </span><span class="kw">mean</span>(y) <span class="op">-</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(x)</a>
<a class="sourceLine" id="cb181-9" title="9"></a>
<a class="sourceLine" id="cb181-10" title="10"><span class="co"># Find residuals (response - predicted values)</span></a>
<a class="sourceLine" id="cb181-11" title="11">e &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>beta0 <span class="op">-</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>x</a>
<a class="sourceLine" id="cb181-12" title="12"></a>
<a class="sourceLine" id="cb181-13" title="13"><span class="co"># Find estimate for the variability around the regression line</span></a>
<a class="sourceLine" id="cb181-14" title="14">sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>(e<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(n<span class="dv">-2</span>))</a>
<a class="sourceLine" id="cb181-15" title="15"></a>
<a class="sourceLine" id="cb181-16" title="16"><span class="co"># Find the sums of the squares fo the Xs (variation in X)</span></a>
<a class="sourceLine" id="cb181-17" title="17">ssx &lt;-<span class="st"> </span><span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb181-18" title="18"></a>
<a class="sourceLine" id="cb181-19" title="19"><span class="co"># Find standard error in regression coefficients</span></a>
<a class="sourceLine" id="cb181-20" title="20">seBeta0 &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(x)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>ssx)<span class="op">^</span>.<span class="dv">5</span> <span class="op">*</span>sigma</a>
<a class="sourceLine" id="cb181-21" title="21">seBeta1 &lt;-<span class="st"> </span>sigma <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(ssx)</a>
<a class="sourceLine" id="cb181-22" title="22"></a>
<a class="sourceLine" id="cb181-23" title="23"><span class="co"># Find t statistics for both regression coeffients </span></a>
<a class="sourceLine" id="cb181-24" title="24">tBeta0 &lt;-<span class="st"> </span>beta0 <span class="op">/</span><span class="st"> </span>seBeta0</a>
<a class="sourceLine" id="cb181-25" title="25">tBeta1 &lt;-<span class="st"> </span>beta1 <span class="op">/</span><span class="st"> </span>seBeta1</a>
<a class="sourceLine" id="cb181-26" title="26"></a>
<a class="sourceLine" id="cb181-27" title="27"><span class="co"># Find p value for regression coefficients</span></a>
<a class="sourceLine" id="cb181-28" title="28">pBeta0 &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(tBeta0), <span class="dt">df =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb181-29" title="29">pBeta1 &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(tBeta1), <span class="dt">df =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb181-30" title="30"></a>
<a class="sourceLine" id="cb181-31" title="31">coefTable &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(beta0, seBeta0, tBeta0, pBeta0), <span class="kw">c</span>(beta1, seBeta1, tBeta1, pBeta1)) </a>
<a class="sourceLine" id="cb181-32" title="32"></a>
<a class="sourceLine" id="cb181-33" title="33"><span class="kw">colnames</span>(coefTable) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Estimate&quot;</span>, <span class="st">&quot;Std. Error&quot;</span>, <span class="st">&quot;t-Value&quot;</span>, <span class="st">&quot;P(&gt;|t|)&quot;</span>)</a>
<a class="sourceLine" id="cb181-34" title="34"><span class="kw">rownames</span>(coefTable) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Intercept&quot;</span>, <span class="st">&quot;x&quot;</span>)</a>
<a class="sourceLine" id="cb181-35" title="35"></a>
<a class="sourceLine" id="cb181-36" title="36">coefTable</a></code></pre></div>
<pre><code>##            Estimate Std. Error   t-Value      P(&gt;|t|)
## Intercept -259.6259   17.31886 -14.99094 2.523271e-19
## x         3721.0249   81.78588  45.49715 6.751260e-40</code></pre>
<p>This output should (if done correctly) give you the exact same as the output from a linear model created using the <code>lm()</code> function with two lines of code.</p>
<p>Lets find out:</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" title="1"><span class="co"># Run the same linear modeling function:</span></a>
<a class="sourceLine" id="cb183-2" title="2">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb183-3" title="3"><span class="kw">summary</span>(fit)<span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) -259.6259   17.31886 -14.99094 2.523271e-19
## x           3721.0249   81.78588  45.49715 6.751260e-40</code></pre>
</div>
<div id="getting-a-confidence-interval" class="section level3">
<h3><span class="header-section-number">20.7.2</span> Getting a Confidence Interval</h3>
<p>Typing <code>summary(fit)</code> gies you the full output form the <code>lm()</code> function.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" title="1">sumCoef &lt;-<span class="st"> </span><span class="kw">summary</span>(fit)<span class="op">$</span>coefficients</a>
<a class="sourceLine" id="cb185-2" title="2">IntEst &lt;-<span class="st"> </span>sumCoef[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dt">df =</span> fit<span class="op">$</span>df) <span class="op">*</span><span class="st"> </span>sumCoef[<span class="dv">1</span>,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb185-3" title="3">SlopeEst&lt;-<span class="st"> </span>(sumCoef[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dt">df =</span> fit<span class="op">$</span>df) <span class="op">*</span><span class="st"> </span>sumCoef[<span class="dv">2</span>,<span class="dv">2</span>])<span class="op">/</span><span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb185-4" title="4"></a>
<a class="sourceLine" id="cb185-5" title="5">IntEst</a></code></pre></div>
<pre><code>## [1] -294.4870 -224.7649</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" title="1">SlopeEst</a></code></pre></div>
<pre><code>## [1] 355.6398 388.5651</code></pre>
<p>This effectively tells us that for every 0.1 carat increat in diamond mass, we are 95% confident that the price increase in singapore dollars will be between $356 and $389.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="quiz-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="prediction.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
